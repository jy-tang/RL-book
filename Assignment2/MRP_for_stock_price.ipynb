{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Callable, Tuple, Optional, Mapping\n",
    "import numpy as np\n",
    "import itertools\n",
    "from rl.distribution import Categorical, Constant\n",
    "from rl.markov_process import MarkovRewardProcess\n",
    "from rl.gen_utils.common_funcs import get_logistic_func, get_unit_sigmoid_func\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define\n",
    "\n",
    "$$a_k(s) =E[f(S_{t+k})|S_t = s]$$.\n",
    "\n",
    "We have recursive relation\n",
    "\n",
    "$\\begin{equation}\n",
    "E[f(S_{t+k})|S_t = s] = \\sum_{S_{t+1}}P(S_{t}=s,S_{t+1}) E[f(S_{t+k})|S_{t+1}]\n",
    "\\end{equation}$\n",
    "\n",
    "Therefore we can get\n",
    "\n",
    "$\\begin{equation}\n",
    "a_k(s) = \\sum_{s'} P(s,s') a_{k-1}(s')\n",
    "\\end{equation}$\n",
    "\n",
    "In this stock price case, we have that\n",
    "\n",
    "$\\begin{equation}\n",
    "a_k(s) = p\\times a_{k-1}(s+1) + (1-p) \\times a_{k-1}(s-1) \\tag{1}\n",
    "\\end{equation}$\n",
    "\n",
    "The value function is defined as\n",
    "\n",
    "$\\begin{equation}\n",
    "V(s) = \\sum_{k=1}^{\\infty} \\gamma^{k-1} a_k(s)\n",
    "\\end{equation}$\n",
    "\n",
    "Sum $k$ on the both sides of Eq $(1)$ we get recursive equation for $V(s)$\n",
    "\n",
    "$V(s) = pf(s+1) + (1-p)f(s-1) + p \\gamma V(s+1) + (1-p)\\gamma V(s-1)$\n",
    "\n",
    "We can calculate $V(s)$ recursively. The problem is that we have infinite number of states and there are no \"initial condition\" provided.\n",
    "Noting that $gamma < 1, p<1$, we can solve this problem by presetting some accuracy requirement. And if $\\gamma^n < accuracy$, we stop the recursion."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class StateMP1:\n",
    "    price: int\n",
    "\n",
    "@dataclass\n",
    "class StockPriceMRP1(MarkovRewardProcess[StateMP1]):\n",
    "    level_param: int  # level to which price mean-reverts\n",
    "    gamma: float   # gamma for gain\n",
    "    f: Callable[[int], float]     # function for reward\n",
    "    alpha1: float = 0.25  # strength of mean-reversion (non-negative value)\n",
    "    accuracy: float = 1e-3\n",
    "\n",
    "    def up_prob(self, state: StateMP1) -> float:\n",
    "        return get_logistic_func(self.alpha1)(self.level_param - state.price)\n",
    "\n",
    "    def transition_reward(self, state: StateMP1) -> Categorical[Tuple[StateMP1, float]]:\n",
    "        up_p = self.up_prob(state)\n",
    "\n",
    "        return Categorical({\n",
    "            (StateMP1(state.price + 1),self.f(StateMP1(state.price + 1))): up_p,\n",
    "            (StateMP1(state.price - 1),self.f(StateMP1(state.price + 1))): 1 - up_p\n",
    "        })\n",
    "\n",
    "    def get_value_function(self,state:StateMP1)\\\n",
    "            ->float:\n",
    "        def helper(state:StateMP1,order:int):\n",
    "            result = 0\n",
    "            if self.gamma**order <= self.accuracy:\n",
    "                return result\n",
    "\n",
    "            p = self.up_prob(state)\n",
    "            result = p*self.f(state.price+1) + (1-p)*self.f(state.price+1)+ \\\n",
    "                     p*self.gamma*helper(StateMP1(price = state.price+1),order+1) + \\\n",
    "                     (1-p)*self.gamma*helper(StateMP1(price=   state.price-1),order+1)\n",
    "            return result\n",
    "        return helper(state,0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "34.62629541699808"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reward_function(price:float)->float:\n",
    "    return price/3\n",
    "\n",
    "gamma:float = 0.5\n",
    "level_param: int = 100\n",
    "accuracy:float = 1e-3\n",
    "\n",
    "\n",
    "mp = StockPriceMRP1(gamma = gamma,level_param=level_param,f = reward_function,accuracy=accuracy)\n",
    "mp.get_value_function(StateMP1(price=50))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}